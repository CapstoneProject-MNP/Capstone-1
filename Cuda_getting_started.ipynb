{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cuda_getting_started.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LykpCIQpXVWx"
      },
      "source": [
        ">Refresh the Cloud Instance of CUDA On Server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm26-J4be1ZT",
        "outputId": "8be1ca07-9ccd-4fb9-9b7b-1f9213cdc28e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3gI_GtXR94"
      },
      "source": [
        ">Install CUDA Version 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBzAnG8gfl_k",
        "outputId": "c62f65eb-80df-4119-99e0-579eefe989aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDAmiIi3Xtm-"
      },
      "source": [
        ">Check the Version of CUDA "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfeHLHz9f7Xm",
        "outputId": "c7af0000-c4f4-480d-adce-c799f1cb050f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Wed_Apr_11_23:16:29_CDT_2018\n",
            "Cuda compilation tools, release 9.2, V9.2.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2RDvrKBX0et"
      },
      "source": [
        ">Execute the given command to install a small extension to run nvcc from Notebook cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67qN3REogIpW",
        "outputId": "930a07d6-a027-42ff-fd38-31cf72cc1f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-n5hzf6_y\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-n5hzf6_y\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=bfab558f624a5f3d4bbab6352ca39f557de1e9a7e3db34be7cab4748c4657f36\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bcar73kc/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xpkOco_X6m0"
      },
      "source": [
        ">Load the extension using this code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spLelZkNgOjS",
        "outputId": "79ca205b-d646-46f9-ef2b-d5cf4733e7da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "directory /content/src already exists\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUhOP03gYCJs"
      },
      "source": [
        ">To check the Code run the following snippet in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0px4wXPfgbYq",
        "outputId": "6ce06e2b-8542-4b70-caca-a9c0070c2c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c) \n",
        "{\n",
        "    *c = *a + *b;\n",
        "}\n",
        "\n",
        "int main() \n",
        "{\n",
        "    // host copies of variables a, b & c\n",
        "    int a, b, c;\n",
        " \n",
        "    // device copies of variables a, b & c\n",
        "    int *d_a, *d_b, *d_c;\n",
        " \n",
        "    // Allocate space for device copies of a, b, c\n",
        "    int size = sizeof(int);\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "  \n",
        "    // Setup input values  \n",
        "    c = 0;\n",
        "    a = 3;\n",
        "    b = 5;\n",
        "  \n",
        "    // Copy inputs to device\n",
        "    cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "  \n",
        "    // Launch add() kernel on GPU\n",
        "    add<<<1,1>>>(d_a, d_b, d_c);\n",
        "  \n",
        "    // Copy result back to host\n",
        "    cudaError err = cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "    if(err!=cudaSuccess) \n",
        "    {\n",
        "        printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "    }\n",
        "  \n",
        "    printf(\"result is %d\\n\",c);\n",
        "  \n",
        "    // Cleanup\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "  \n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result is 8\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYWkA7fd4RXr"
      },
      "source": [
        "Vector Addition implementation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poO92KCs4pyy",
        "outputId": "652365e6-bb20-4f23-da6d-1d17441bd4a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "%%cu\n",
        "#include \"stdio.h\"\n",
        "#define N 10\n",
        "\n",
        "void add(int *a, int *b, int *c)\n",
        "{\n",
        "    int tID = 0;\n",
        "    while (tID < N)\n",
        "    {\n",
        "        c[tID] = a[tID] + b[tID];\n",
        "        tID += 1;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "     int a[N], b[N], c[N];\n",
        "    // Fill Arrays\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        a[i] = i,\n",
        "        b[i] = 1;\n",
        "    }\n",
        "    \n",
        "    add (a, b, c);\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        printf(\"%d + %d = %d\\n\", a[i], b[i], c[i]);\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 + 1 = 1\n",
            "1 + 1 = 2\n",
            "2 + 1 = 3\n",
            "3 + 1 = 4\n",
            "4 + 1 = 5\n",
            "5 + 1 = 6\n",
            "6 + 1 = 7\n",
            "7 + 1 = 8\n",
            "8 + 1 = 9\n",
            "9 + 1 = 10\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf7G5Rhh9wYx"
      },
      "source": [
        "2-D Array Addition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeE9LzMx8ScF",
        "outputId": "80f5d449-80e2-4be8-e8a6-1929aa96051a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%cu\n",
        "#include \"stdio.h\"\n",
        "#define COLUMNS 3\n",
        "#define ROWS 2\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c)\n",
        "{\n",
        "    int x = blockIdx.x;\n",
        "    int y = blockIdx.y;\n",
        "    int i = (COLUMNS*y) + x;\n",
        "    c[i] = a[i] + b[i];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int a[ROWS][COLUMNS], b[ROWS][COLUMNS], c[ROWS][COLUMNS];\n",
        "    int *dev_a, *dev_b, *dev_c;\n",
        "    cudaMalloc((void **) &dev_a, ROWS*COLUMNS*sizeof(int));\n",
        "    cudaMalloc((void **) &dev_b, ROWS*COLUMNS*sizeof(int));\n",
        "    cudaMalloc((void **) &dev_c, ROWS*COLUMNS*sizeof(int));\n",
        "    for (int y = 0; y < ROWS; y++) // Fill Arrays\n",
        "        for (int x = 0; x < COLUMNS; x++)\n",
        "        {\n",
        "            a[y][x] = x;\n",
        "            b[y][x] = y;\n",
        "        }\n",
        "    cudaMemcpy(dev_a, a, ROWS*COLUMNS*sizeof(int),\n",
        "    cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, ROWS*COLUMNS*sizeof(int),\n",
        "    cudaMemcpyHostToDevice);\n",
        "    dim3 grid(COLUMNS,ROWS);\n",
        "    add<<<grid,1>>>(dev_a, dev_b, dev_c);\n",
        "    cudaMemcpy(c, dev_c, ROWS*COLUMNS*sizeof(int),\n",
        "    cudaMemcpyDeviceToHost);\n",
        "    for (int y = 0; y < ROWS; y++) // Output Arrays\n",
        "    {\n",
        "        for (int x = 0; x < COLUMNS; x++)\n",
        "        {\n",
        "            printf(\"[%d][%d]=%d \",y,x,c[y][x]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0][0]=0 [0][1]=1 [0][2]=2 \n",
            "[1][0]=1 [1][1]=2 [1][2]=3 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
